% TODO map provincial-class maps omitting single-province genera?
% TODO same maps but with rank order risk?
% TODO the cross plots of human threat, climate velocity, and intrinsic risk on global map?

\documentclass[11pt]{article}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{url}
\usepackage[nottoc,numbib]{tocbibind} % to add bibliography to TOC
\textheight 20.5cm
\setlength\parskip{0.11in}
\setlength\parindent{0in}
\let\proglang=\textsf
\let\pkg=\textbf
\let\fn=\texttt

\usepackage[nofiglist,notablist,nomarkers,figuresfirst]{endfloat}
\renewcommand{\theposttable}{S\arabic{posttbl}}
\renewcommand{\thepostfigure}{S\arabic{postfig}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\figurename}{Figure}
\renewcommand{\tablename}{Table}

\begin{document}

<<set-knitr-options, cache=FALSE, echo=FALSE>>=
library("knitr")
opts_chunk$set(fig.align='center', fig.pos="htpb", cache=TRUE, echo=FALSE,
message=FALSE, autodep=TRUE, fig.path='../figs/', fig.width=6, par=TRUE)
opts_chunk$set(warning=FALSE, message=FALSE, tidy=FALSE, refresh=TRUE,
  cache.path="../cache/", cache.lazy=FALSE, size="small")
opts_chunk$set(dev = 'pdf')
opts_knit$set(out.format = "latex")
thm <- knit_theme$get("solarized-light.css")
knit_theme$set(thm)
@

\title{Supplementary Materials for Paleontological Baselines for Evaluating
Contemporary Extinction Risk in Coastal Oceans}
\author{Seth Finnegan\textsuperscript{$\ast$} \and Sean C. Anderson \and Paul
G. Harnik \and Carl Simpson \and Derek P. Tittensor \and Jarrett E. Byrnes \and
Zoe V. Finkel \and David R. Lindberg \and Lee Hsiang Liow \and Rowan Lockwood
\and Heike K. Lotze \and Craig M. McClain \and Jenny L. McGuire \and
Aaron O'Dea \and John M. Pandolfi}
\date{}
\maketitle

\textsuperscript{$\ast$}Corresponding author. E-mail sethf@berkeley.edu

This PDF file includes:\\
Figs.\ S1 to SXX\\
References

\clearpage

\tableofcontents
\clearpage

% Load Fig S1 here to make sure it's the first figure.
% Supplementary figures all get printed at the end because we loaded the
% endfloat LaTeX package.
\begin{figure}[htbp]
\centering
\includegraphics[width=6in]{../static-figs/didactic_method.pdf}
\caption{Schematic illustration of the sequence of steps used to build the modern genus range dataset and to make intrinsic risk predictions for modern genera from the Neogene fossil record.}
\label{fig:didactic}
\end{figure}

\section{Introduction}

TODO introduce what's in this document.

TODO store data somewhere and link to it here.

This document is written with the \pkg{knitr} package \cite{xie2013a,xie2013b,xie2013c} for the \proglang{R} statistical environment \cite{r2013}. It can be re-created by running \fn{knitr::knit2pdf()} on the \texttt{.Rnw} file. A number of functions that are used in this analysis have
been compiled into an \proglang{R} package \pkg{paleorisk}.

You can install the package by downloading the \texttt{paleorisk} folder from
\url{https://github.com/seananderson/riskmaps} and running:

<<install-paleorisk, eval=FALSE, echo=TRUE>>=
install.packages("/your/path/to/riskmaps/paleorisk/", repos = NULL, type = "source")
@

<<load-packages, cache=FALSE>>=
library("paleorisk")
library("plyr")
library("dplyr")
library("gdata")
library("reshape2")
library("ggplot2")
library("DMwR")
library("gbm")
library("maps")
library("mapproj")
library("maptools")
library("RColorBrewer")
library("PBSmapping")
library("fields")
@

<<gpclibPermit, cache=FALSE, echo=FALSE, results='hide'>>=
gpclibPermit()
@

<<preamble-work, cache=FALSE, echo=FALSE, results=FALSE>>=
theme_set(theme_bw())
rversion <- capture.output(sessionInfo())[[1]]
x <- capture.output(sessionInfo())
other_line <- grep("other attached", x)
pkgs <- x[(other_line+1):(other_line + 5)]
@

We used \Sexpr{rversion} and the following \proglang{R} packages:

Although the code in this document has been suppressed for brevity, the complete analysis is available at \url{http://github.com/seananderson/riskmaps}. \textit{Currently a private repository.}

<<versions, echo=FALSE, results=TRUE, cache=FALSE>>=
pkgs
@

\section{Description and preparation of the data}

\subsection{Choice of taxa}

We initially focused on groups of marine organisms that are common constituents of coastal ecosystems and have relatively well-sampled modern and Neogene distributions. These include bivalves, echinoids, elasmobranchs, gastropods, marine mammals, scleractinian corals, and testudines. We omitted groups with intrinsically low preservation potential (i.e.,\ groups consisting solely of soft-bodied organisms, parasitic life habit, and

TODO Paul will work on this section

\textit{list of variety of traits here that are associated with low preservation rates (Crampton and Cooper and others NZ preservation reference in Geology; Valentine et al. 2006 PNAS paper on preservation potential in bivalves) such as (example) and (example)}. Some additional groups were also omitted due to the limited taxonomic resolution of fossil occurrences. Ray-finned fishes, for example, are diverse and abundant in modern and ancient seas, yet their fossil record consists primarily of isolated otoliths and teeth which frequently confounds attempts to identify remains to the genus or species levels (REF). Where possible we also consulted taxonomic experts to see if the biogeographic diversity patterns recorded in our raw data sources (described below) were consistent with their knowledge of global diversity patterns in their group of expertise in select instances this resulted in the exclusion of groups with generally high preservation potential (i.e.,\ foraminifera, brachiopoda, and ostracoda). With additional targeted sampling and literature compilation, these groups hold promise for inclusion in the types of analyses we present in the main text.

\subsection{Sources of contemporary data}

Modern occurrence data for major marine groups came from two primary sources. For most groups, occurrence data were downloaded from the Ocean Biogeographic Information System (OBIS, \url{http://www.iobis.org/}) \cite{obis}. OBIS is a marine biogeographical database initially developed as part of the Census of Marine Life, and currently containing around 37 million geolocated records of marine taxa. These data were downloaded on TODO date using the following selection criteria: TODO. The complete dataset consists of xx occurrences for yy taxa (supplementary figure showing data coverage --- e.g.,\ with cells color coded by occurrence frequency?).

TODO This area perhaps is ripe for Seth or David Lindberg to try their hand at

For cetaceans and sharks, OBIS data were not used, since recent efforts have compiled range maps at global scales for all species in these groups \cite{schipper2008, lucifora2011}, obviating the need to correct for sampling effort. Data were quality-controlled as per Ref.\ \cite{tittensor2010}. These range maps were converted to occurrence data by laying down a grid of z cell-size resolution and at each intersection generating an occurrence for that genus. OBIS remains the largest single source of modern-day geolocated marine biological data, synthesising many different data sources and individual databases; however, the sampling is very uneven by taxa, by approach, by region, and by depth \cite{webb2010}, so significant caution is necessary to account for these issues of sampling effort when using the database. The database tends to be best applied to relatively well-studied and well-described taxa (e.g.\ fishes, corals).

TODO we should include a few recent sample references here

\subsection{Sources of paleontological data}

All of the fossil occurrence data used for this study were downloaded from the Paleobiology Database (PaleoDB, \url{http://paleobiodb.org}), a global compilation of the spatial and temporal occurrences of taxa in the fossil record. The Paleobiology Database has been used in previous investigations of marine extinction rates \cite{harnik2012} (Alroy 2010, Foote 2008, Hannisdal \& Peters 2011, etc.), extinction selectivity (Heim and Peters 2011, other refs), and geographic range (Payne and Finnegan 2007 PNAS, Harnik et al. 2012 Proc B).

We downloaded genus occurrences from the Paleobiology Database on XX June 2013 [?]. We used the following protocol to exclude occurrences which do not meet a minimum level of taxonomically certainty: First, multiple occurrences of a genus within a collection were lumped.[?] Second, only genus names are used, we did not treat subgenera as genera. Third, we excluded generically indeterminate occurrences but kept specifically indeterminate occurrences if they have a genus name. Forth, we excluded genus names that where informal and qualified by \texttt{aff.}, \texttt{?}, \texttt{cf.}, or quotation marks. We assigned occurrences to one of four Neogene time intervals: the Early Miocene, Middle Miocene, Upper Miocene, and the Plio-Pleistocene. We downloaded paleolatitude and paleolongitude information for each occurrence. Our PaleobioDB dataset contains a total of, XX occurrences of XX genera.

TODO include figure showing distribution of Neogene localities on present-day global map?

\subsection{Standardizing the taxonomic data}

First, standardization of taxonomy and removal of erroneous names or taxa (e.g.\ pulmonate gastropods) that do not belong.  Next, genus names from OBIS matched to higher taxonomic groups using the WORMS database.  Higher taxonomy of WORMS and of PDBD standardized to the greatest degree possible.

\subsection{Choice of predictor variables}

TODO ADD HERE

\subsection{Interpolation of OBIS occurrence data}

Sampling of species' distributions in the contemporary OBIS data set is incomplete. Therefore, we used an interpolation algorithm to infer the contemporary distribution of genera. We assumed that if a genus was identified within a biogeographic realm \cite{spalding2007}, it was likely to be found throughout that realm. We used a minimum-bounding-box method to interpolate within biogeographic realms across biogeographic provinces. We are assuming that the interpolated contemporary biogeographic provinces cover the ``true'' range. A similar minimum-bounding-box approach has been used in the literature before to account for variable sampling, for example Ref.~\cite{belanger2012}. We did not interpolate the marine mammals or elasmobranch datasets since these were based on range maps.

To apply a bounding-box approach to a globe, we needed to decide on a maximum gap between points to be considered part of the same box. We split gaps of $90\,^{\circ}$ longitude or greater into separate bounding boxes. For the most part, this rule did not affect our results, since most biogeographic realms were smaller than $90\,^{\circ}$.

As one illustrative example, here's a simplified plot of the interpolation process for the genus Petrophyllia, a scleractinian coral:

\includegraphics[width=2.5in]{../static-figs/petrophyllia-cropped.pdf}

We've only shown the biogeographic realm containing any contemporary observations (all shaded region combined). Individual polygons represent biogeographic regions. We've shown two occurrences as red crosses. We then draw a minimum bounding box around those observations (the rectangle) and shade with a darker grey the single biogeographic province crossed by the bounding box. We record this darker biogeographic province as containing the genus.

As another example on a larger scale, the following plot shows the interpolations for 6 genera. The red crosses indicate sampling observations in the OBIS database. The various biogeographic realms are shown in different colour shadings. The outlined provinces are all the provinces within any realm that has occurrences. The grey-shaded polygons represent biogeographic provinces that are added based on the minimum-bounding-box interpolation scheme. Outlined provinces that aren't shaded are provinces that the bounding box didn't overlap. Keep in mind that some realms wrap from one side of the plot to the other.

\includegraphics[width=\textwidth]{../static-figs/province_interpolation_test_eg.pdf}

For the contemporary dataset, we took the interpolated provinces, overlaid an equal-area grid, recorded the centre points of that grid for all cells that overlapped a province, and then calculated the range statistics based on the centre points from the grid overlay.

Our equal-area grid was divided into 45 east-west cells and 14 north-south cells. The longitudes started at $-180\,^{\circ}$ and increased by $8\,^{\circ}$ to $180\,^{\circ}$. The latitude values of the grid line (in degrees) were: -74.8, -55.6, -43.3, -33.1, -24, -15.5, -7.3, 0.7, 8.7, 17, 25.5, 34.8, 45.3, 58.2, 81.8. We recorded the centre coordinates for all grid cells that overlapped with a province with observations or interpolated observations. TODO ADD CENTRE COORDINATES.

For the paleontological dataset, we overlaid the same equal-area grid, took the centre points of the grid cells for cells that overlapped any occurrences, and calculated the range statistics on the centre points from the grid overlay.

<<interpolation, eval=FALSE>>=
# Run the OBIS interpolation
# Will take a very long time to run and requires a server with a large
# quantity of memory.
# TODO clean up these files the paths are right:
source("../r/README_interpolation.R")
@

\subsection{Calculating the predictor variables}

TODO what and why

TODO Paul: either "habitat" is not the right descriptor for each of these or "richness" should go in a different section

We will start by standardizing a variety of habitat-relative characteristics within each geologic stage. This is an important step to make some habitat characteristics (richness, occupancy, occurrences) comparable across periods, an in particular, between the paleontological data and the contemporary data. Given the substantially different sampling methods within the paleontological and contemporary records, the absolute values of richness, occupancy, and occurrences are not comparable. We therefore standardize them to values between 0 and 1 within each interval. The other variables (e.g.\ latitude variables and great circle distance) are still comparable between the paleontological and contemporary records --- a degree latitude is still a degree latitude and a kilometre is still a kilometre.

% The code in \texttt{extract-ranges.Rnw} creates the \proglang{R} data object \texttt{modern\_and\_paleo\_ranges.rds}.

<<extract-ranges, child='extract-ranges.Rnw', eval=TRUE, echo=FALSE, results='hide'>>=
@

\subsection{Standardizing the predictor data}

% We will standardize the predictor data with the following \proglang{R} code:

<<standardize-predictors>>=
dat <- readRDS("../data/modern_and_paleo_ranges.rds")
dat <- rename(dat, c("Interval" = "Interval_Name",
    "MaxAbsLat" = "MaxLat", "MinAbsLat" = "MinLat",
    "group" = "MatchTaxon", "top" = "stage_top",
    "MeanAbsLat" = "mean_lat", "Ex" = "Extinct.in.stage"))
dat <- subset(dat, !class %in% c("Foraminifera", "Testudines", "Malacostraca"))
#mean.lats <- readRDS("../data/genus-mean-occurence-lats.rds")
#dat <- merge(data, mean.lats)
neog <- ddply(dat, "Interval_Name", standardize_data)
saveRDS(neog, file = "../data/stand-predictors-cen-obis.rds")
@

\section{Modelling contemporary extinction risk with paleontological data}

\subsection{Choice of modelling framework}

We modelled intrinsic contemporary extinction probability from paleontological data using a form of ensemble learning called generalized boosting models (GBMs; \cite{friedman2001}). \textit{Ensemble learning} refers to how the final model is a product of many weakly informative models fit in succession. Compared to parametric modelling, GBMs (along with other forms of machine learning) make minimal assumptions about the relationship between predictors and response and prioritize predictive performance over probabilistic inference about the model itself \cite{elith2008}.

Boosting models work, in general, by building a sequence of models, each fit to the residuals of the previous model with larger residuals being given stronger weights. This means that each subsequent model focuses more heavily on data which were poorly fit by previous models. In theory, this ensemble of weak models can be combined to produce one strong overall predictive model with reduced bias compared to other machine learning methods, such as random forests \cite{elith2008}. Boosted tree methods have been shown to outperform other machine learning methods in many cases \cite{caruana2006} and are commonly used in applied prediction problems (e.g. by Yahoo for website rankings; \cite{cossock2008}).

We fit GBMs with the \pkg{gbm} package \cite{gbm2013} for the \proglang{R} statistical language and environment \cite{r2013}. The \pkg{gbm} package implements GBMs based on Ref.\ \cite{friedman2001} with some minor modifications \cite{gbm2013}. Further, the \pkg{gbm} package implements the stochastic method proposed in Ref.\ \cite{friedman2001} in which a random subsample of the data is chosen at each model iteration. This random subsample is used to fit the model before computing residuals for that step thereby reducing chances of overfitting the data. Specifically, we chose to leave out 50\% of the data as a random subset on each iteration --- the default in the \texttt{gbm()} function.

\subsection{Model building, testing, and calibration}

% We will load the standardized data and subset it for the Neogene period. The contemporary data are also contained in this data frame with \texttt{stage\_top = 0}. Therefore, we will also exclude the contemporary dataset from what we call \texttt{neog}.

<<load-data>>=
neog <- readRDS("../data/stand-predictors-cen-obis.rds")
# can throw out less than 22 - neogene only
neog <- droplevels(subset(neog, neog$stage_top < 22 &
    neog$stage_top != 0))
@

We will start by building GBM models and testing their ability to predict data separate from the data they are built on. This is called out-of-sample prediction or cross validation. We build models on one part of the data (in-sample data) and then test on the rest of the data (out-of-sample data). We are building our GBM models on the entire Neogene paleontological dataset to pool predictive power from range-characteristics. However, we are interested in unbiased predictions at the taxonomic class level. Therefore, we will examine out-of-sample prediction at the class level and use class-level cross validation to calibrate our models.

\fn{validate\_gbm()} in the \pkg{paleorisk} package is our main validation and calibration function. This function deals with splitting the data into training (fitting) and testing portions, builds a GBM on the training portion, and then returns predictions and classification statistics on the testing set. We will start by testing some GBM models. To start with, we will build the model 25 times, each time training the model on a random 50\% of the data and testing it on the other 50\%. Then we will record the observed mean extinction probability for each predicted bin value within each taxonomic class. For example, we can group all predicted extinction values for bivalves into bins from 0 to 1 in 0.05 increments. Then we can calculate the mean observed extinction probability for each of those bins. Because we're building and testing the model on independent datasets, this is a good test of the out-of-sample predictive ability of our modelling approach.

<<test-gbm1>>=
val_test <- rdply(20, validate_gbm(neog, shrinkage = 0.05,
  interaction.depth = 1, n.trees = 300, use_weights = TRUE)$bin_validation)
saveRDS(val_test, file = "../data/val_test.rds")
@

Next, we will compute some summary statistics for the observed extinction probability at each bin across our replicates. We will use the \fn{summarize\_val\_test()} from our \pkg{paleorisk} package. This computes means and 95\% confidence intervals (based on likelihood profiles) for each validation bin.

TODO expand on this: those blue calibration dots are based on a binomial GLM of the true underlying observed 0s (not extinct) and 1s (extinct). I.e. they are the mean estimate from a binomial GLM fit to the black dots (proportions) with weights = to the sample size. So it's not really a mean of a mean, it's a true mean of all observed genera in that bin, but the black dots help illustrate what's going on.

<<test-gbm1-summary>>=
val_test_summarized <- ddply(val_test, c("class", "gbm_pred_binned"),
  summarize_val_test)
@

An example from one replicate:

<<single-cv-rep, fig.width=7.5, fig.height=7>>=
ggplot(subset(val_test, .n == 1),
  aes(gbm_pred_binned, obs_ext_prob)) +
  geom_point(alpha = 0.9) +
  geom_abline(intercept = 0, slope = 1) +
  facet_wrap(~class) +
  scale_size(trans = "log10") + coord_fixed(ratio = 1) +
  ylim(0, 1) + xlim(0, 1) +
  xlab("Out-of-sample GBM-predicted extinction probability") +
  ylab("Observed extinction probability (one iteration)") +
  labs(size = "Sample #")
@

We can plot these data to test for any non-linear biases in our predictions. Translucent black dots show mean observed extinction probabilities for individual replicates. Blue dots show mean observed extinction probabilities across replicates and line segments show 95\% confidence intervals. The area of the dots corresponds to the median number of extinction/survival observations in that bin across replicates. TODO EXPLAIN BLACK DOTS AND ADD FIGURE FOR ONE CV ITERATION.

<<test-gbm1-bias-plot, fig.width=7.5, fig.height=7, echo=FALSE>>=
ggplot(val_test_summarized,
  aes(gbm_pred_binned, mean_observed)) +
  geom_point(data = val_test, aes(gbm_pred_binned, obs_ext_prob),
    alpha = 0.1) +
  geom_abline(intercept = 0, slope = 1) +
  geom_linerange(aes(ymin = l, ymax = u), colour = "#4E9DF0") +
  geom_point(aes(size = median_sample_n), colour = "#4E9DF0") +
  facet_wrap(~class) +
  scale_size(trans = "log10") + coord_fixed(ratio = 1) +
  ylim(0, 1) + xlim(0, 1) +
  xlab("Out-of-sample GBM-predicted extinction probability") +
  ylab("Observed extinction probability") +
  labs(size = "Median sample #")
@

We can use these observed extinction probabilities (in \texttt{val\_test\_summarized}) as calibration for our GBM-predicted extinction probability in the contemporary dataset. To do this, we take the predicted extinction probability from our GBM model applied to the contemporary dataset, we fit that value into our binning scheme, and we match it up with the empirically-observed mean extinction probability for that bin. This removes the observed non-linear bias in our model \cite{thorson2012}. Put another way, we find our predicted value on the x-axis of the last plot and draw a vertical line up until we meet a blue dot. We then use the value of the blue dot as our calibrated extinction probability. We will come back to that shortly when we apply our model to the contemporary dataset.

Next, we will examine the effect of varying some of the main arguments to the \texttt{gbm()} function. We will test the effect of the \texttt{shrinkage} (the rate of improvement between each tree iteration), \texttt{interaction.depth} (the maximum number of variable interactions), and \texttt{n.trees} (the total number of trees to build) arguments. We will vary each argument one at a time.

<<alternative-gbms>>=
val_test_base <- rdply(20, validate_gbm(neog, shrinkage = 0.05,
    interaction.depth = 1, n.trees = 300,
    use_weights = TRUE)$bin_validation)
val_test_shr <- rdply(20, validate_gbm(neog, shrinkage = 0.01,
    interaction.depth = 1, n.trees = 300,
    use_weights = TRUE)$bin_validation)
val_test_int <- rdply(20, validate_gbm(neog, shrinkage = 0.05,
    interaction.depth = 4, n.trees = 300,
    use_weights = TRUE)$bin_validation)
val_test_ntrees <- rdply(20, validate_gbm(neog, shrinkage = 0.05,
    interaction.depth = 1, n.trees = 1000,
    use_weights = TRUE)$bin_validation)
@

<<summarize-alt-gbms>>=
val_test_base_summ <- ddply(val_test_base,
  c("class", "gbm_pred_binned"), summarize_val_test)
val_test_shr_summ <- ddply(val_test_shr,
  c("class", "gbm_pred_binned"), summarize_val_test)
val_test_int_summ <- ddply(val_test_int,
  c("class", "gbm_pred_binned"), summarize_val_test)
val_test_ntrees_summ <- ddply(val_test_ntrees,
  c("class", "gbm_pred_binned"), summarize_val_test)
@

<<rename-alt-gbms>>=
val_test_base_summ$version <- "Base"
val_test_shr_summ$version <- "Smaller shrinkage"
val_test_int_summ$version <- "Larger interaction"
val_test_ntrees_summ$version <- "More trees"
val_test_alt <- rbind(val_test_base_summ, val_test_shr_summ,
  val_test_int_summ, val_test_ntrees_summ)
@

We will plot out the observed vs.\ predicted extinction probabilities for these 4 versions of the model. We fail to find substantially improved model performance with any of these alternatives, despite considerably increased computational requirements. We therefore continue from here on with the model we refer to as the ``base'' model above.

<<plot-alt-gbms, fig.height=8, fig.width=13, out.width="7in", echo=FALSE>>=
ggplot(val_test_alt,
  aes(gbm_pred_binned, mean_observed)) +
  geom_point(aes(size = median_sample_n)) +
  geom_linerange(aes(ymin = l, ymax = u)) +
  facet_grid(version~class) +
  scale_size(trans = "log10") + coord_fixed(ratio = 1) +
  ylim(0, 1) + xlim(0, 1) +
  xlab("Out-of-sample GBM-predicted extinction probability") +
  ylab("Observed extinction probability") +
  labs(size = "Median sample #")
@

\subsection{Testing predictive performance across geologic stages}

Another way to test the predictive power of our models is to build the model on one geologic stage and predict on another. We will not use our calibration factors in this test keep the code as simple as possible and to minimize computational time.

<<cross-intervals-gbms>>=
stage_df <- expand.grid(stage_train = unique(neog$stage),
  stage_test = unique(neog$stage))
cross_pred <- mdply(stage_df, fit_interval_gbm, dat = neog)
@

We can compare the predictions made from other stages with the predictions from the same stage. This code produces Fig.~\ref{fig:plot-cross-interval-gbms}.

<<plot-cross-interval-gbms, fig.cap="Cross-interval comparison of genus risk estimates from generalized boosting models. The x-axis shows the probability of extinction as predicted by a model built on data from the same stage. The y-axis shows the probability of extinction as predicted by a model built on data from a different stage. The colours show different taxonomic classes. Note the log-distributed x- and y-axes. Since there is some stochasticity involved in the generalized boosting machine fitting routine, there is some variability in predictions within the same stage (the diagonal panels). In general, there is substantial similarity in extinction regimes between succeeding intervals with respect to the evaluated taxonomic and geographic range predictor variables.", fig.width=9, fig.height=7, cache=TRUE, echo=TRUE>>=
# Re-order stage names:
stage_order <- c("Lower Miocene", "Middle Miocene", "Upper Miocene",
  "Plio-Pleistocene")
cross_pred$stage_test <- factor(cross_pred$stage_test,
  levels = stage_order)
cross_pred$stage_train <- factor(cross_pred$stage_train,
  levels = stage_order)

ggplot(cross_pred, aes(pred_self, pred, colour = class)) +
  geom_point(alpha = 0.3) +
  facet_grid(stage_train ~ stage_test) +
  scale_y_log10() + scale_x_log10() +
  scale_colour_brewer(palette = "Set2") +
  xlab("Probability of extinction predicted within the same stage") +
  ylab("Probability of extinction predicted from a different stage") +
  guides(colour = guide_legend(override.aes = list(alpha = 1)))
@

We see that in general there is substantial similarity in extinction regimes between succeeding geologic stages with respect to the evaluated taxonomic and geographic range predictor variables.

\subsection{Evaluating the marginal effects of predictor variables}

We will now look at the marginal effect of each predictor on extinction risk. We can do this through partial dependence plots, as shown in Fig.~1. This procedure finds the marginal effect of each predictor by integrating across all other predictor values using the method described in Ref.~\cite{friedman2001}.

Because there's some stochasticity when running a GBM, we will run our models a number of times, and each time record the marginal effects. We will then take the median and interquartile range of those predictions for plotting.

% First, we will write a function to fit the GBM models to a given stage:

<<shape-data-partial-plots, cache=FALSE>>=
fit_stage_models <- function(dat, stage_name) {
  if(stage_name == "all") {
    d <- dat
  } else {
    d <- dat[dat$stage == stage_name, ]
  }
  w <- paleorisk::get_weights(d$Ex)
  weights <- ifelse(d$Ex == 1, w$ex_weight, w$sur_weight)
  gbm::gbm(Ex ~ richness + occupancy + occurrences + min.lat + max.lat +
    lat.range + mean.lat + great.circle + group, data =
    d, n.trees = 300, interaction.depth = 1,
    distribution = "bernoulli", shrinkage = 0.05, weights = weights)
}
@

% We will fit the models for each stage. Within each stage we will fit the model a number of times:

<<fit-marginal-stage-models>>=
stage_models <- llply(c(stage_order, "all"), function(x)
  rlply(20, fit_stage_models(neog, stage_name = x)))
names(stage_models) <- c(stage_order, "all")
saveRDS(stage_models, file = "../data/stage_models.rds")
@

% And, we will go through the stage-based models and pull out the partial dependence data:

<<pull-out-marginal-data>>=
vars <- c("richness", "occupancy", "occurrences", "min.lat",
  "max.lat", "lat.range", "mean.lat", "great.circle", "group")
partial_dat <- ldply(c(stage_order, "all"), function(stage_name) {
  p2 <- ldply(vars, function(var_name){
    p1 <- ldply(stage_models[[stage_name]], function(x)
      plot.gbm(x, return.grid = TRUE, i.var = var_name,
        type = "response"))
    names(p1) <- c("value", "response")
    p1$predictor <- var_name
    p1
    })
  p2$stage <- stage_name
  p2
})
@

% We will get the median and interquartile range of the marginal effects:

<<summarize-marginal-effects>>=
partial_dat2 <- plyr::ddply(partial_dat,
  c("stage", "predictor", "value"),
  plyr::summarize,
  median = median(response),
  lower = quantile(response, probs = 0.25),
  upper = quantile(response, probs = 0.75))
@

% Because the taxonomic variables are factors (i.e.\ they are words) and the other variables are continuous and numeric, we will split these into separate data frames for plotting:

<<separate-taxonomic-and-numeric-predictions>>=
partial_groups <- partial_dat2[partial_dat2$predictor == "group", ]
partial_continuous <- partial_dat2[partial_dat2$predictor != "group", ]
groups_match <- data.frame(value =
  1:length(unique(neog$group)),
  group = sort(unique(neog$group)), stringsAsFactors = FALSE)
partial_groups <- plyr::join(partial_groups, groups_match)
partial_groups$value <- NULL
partial_groups <- plyr::rename(partial_groups, c("group" = "value"))
@

% We can re-create Fig.~1 in the paper by running the code in \texttt{make-partial-dependence-plot.Rnw}. We will suppress the code here to save space. Note that in this plotting code we centre the marginal effects for each geologic stage for visual purposes (so that the mean marginal effect of each variable is 0.5). We need to do this since the base rate of extinction is different in each geologic stage.

<<partial-plots-base, child='make-partial-dependence-plot.Rnw', echo=FALSE, results='hide'>>=
@

We will also identify relative contribution of taxonomy vs.\ range and occupancy characteristics. To do this, we'll look at the relative importance of each of the GBM predictors using the \texttt{relative.influence()} function in the \pkg{gbm} package, which uses the algorithm as described in Ref.~\cite{friedman2001}:

<<taxonomy-range-contributions, out.width="3in", fig.height=4, fig.width=4>>=
w <- paleorisk::get_weights(neog$Ex)
weights <- ifelse(neog$Ex == 1, w$ex_weight, w$sur_weight)
m_relative <- gbm(Ex ~ richness + occupancy + occurrences + min.lat +
    max.lat + lat.range + mean.lat + great.circle + group,
  data = neog, n.trees = 300, interaction.depth = 1,
  distribution = "bernoulli", shrinkage = 0.05, weights = weights)
ri <- rdply(50, function(x) {
  m_relative <- gbm(Ex ~ richness + occupancy + occurrences + min.lat +
    max.lat + lat.range + mean.lat + great.circle + group,
  data = neog, n.trees = 300, interaction.depth = 1,
  distribution = "bernoulli", shrinkage = 0.05, weights = weights)
  gbm::relative.influence(m_relative, scale. = TRUE,
    sort. = FALSE, n.trees = 300)
  })
ri_median <- apply(ri[,-1], 2, median)
ri_lq <- apply(ri[,-1], 2, function(x) quantile(x, probs = 0.25))
ri_uq <- apply(ri[,-1], 2, function(x) quantile(x, probs = 0.75))

ri_order <- order(ri_median)
ri_median <- ri_median[ri_order]
ri_lq <- ri_lq[ri_order]
ri_uq <- ri_uq[ri_order]

par(xpd = NA, mar = c(4, 8, 1, 1), cex = 0.8)
plot(ri_median, 1:length(ri_median), xlab = "Relative influence", ylab = "",
  xlim = c(0, 1), xaxs = "i", pch = 19, yaxt = "n")
segments(ri_lq, 1:length(ri_median), ri_uq, 1:length(ri_median))
axis(2, at = 1:length(ri_median), labels = names(ri_median), las = 1)
@

The \texttt{group} variable refers to the taxonomic groupings (primarily order) and has the greatest relative importance followed by the great circle distance of range.

\subsection{Predicting contemporary extinction risk with paleontological models}

We will use our GBM model built on the entire Neogene period to predict extinction risk in the contemporary dataset. Because of the slight stochasticity from run to run of a GBM, we will run our model a number of times and take the average predictions.

<<build-main-paleo-model>>=
w <- paleorisk::get_weights(neog$Ex)
weights <- ifelse(neog$Ex == 1, w$ex_weight, w$sur_weight)

m <- rlply(50, gbm(Ex ~ richness + occupancy + occurrences + min.lat +
    max.lat + lat.range + mean.lat + great.circle + group,
  data = neog, n.trees = 300, interaction.depth = 1,
  distribution = "bernoulli", shrinkage = 0.05, weights = weights))
@

% Next, we will load the contemporary data:

<<load-modern-data>>=
temp_dat <- readRDS("../data/stand-predictors-cen-obis.rds")
modern <- subset(temp_dat, stage == "Modern_merged")
modern$stage <- "Modern"
rm(temp_dat)
@

We will look at the distribution of the predictors across the taxonomic classes in the contemporary dataset:

<<modern-predictor-distributions, fig.width=13, fig.height=12>>=
modern_long <- reshape2::melt(modern, id.vars = c("class", "group", "genus"),
  measure.vars = c("richness", "occupancy", "occurrences",
    "min.lat", "max.lat", "lat.range", "mean.lat", "great.circle"))
p <- ggplot(modern_long, aes(value)) +
  geom_histogram(aes(colour = class, fill = class)) +
  facet_grid(class~variable, scales = "free")
@

And the distribution of predictors across the taxonomic class in the paleontological dataset:

<<paleo-predictor-distributions, fig.width=13, fig.height=12>>=
paleo_long <- reshape2::melt(neog, id.vars = c("class", "group", "genus"),
  measure.vars = c("richness", "occupancy", "occurrences",
    "min.lat", "max.lat", "lat.range", "mean.lat", "great.circle"))
p <- ggplot(paleo_long, aes(value)) +
  geom_histogram(aes(colour = class, fill = class)) +
  facet_grid(class~variable, scales = "free")
@

% And predict the contemporary intrinsic extinction risk from the paleontological models. We will take the average prediction across our multiple runs:

<<predict-risk-modern>>=
predictions <- laply(m, function(x)
  gbm::predict.gbm(x, newdata = modern, type = "response",
    n.trees = 300))
modern$pred <- apply(predictions, 2, mean)
@

% We will use our calibration factors on our predictions:

<<calibrate-risk-modern>>=
modern$gbm_pred_binned <- assign_bins(modern$pred)
modern <- plyr::join(modern,
  val_test_summarized[,c("class", "gbm_pred_binned", "mean_observed")],
  by = c("class", "gbm_pred_binned"))
# modern <- modern[!is.na(modern$mean_observed), ]
# or skip calibration:
# modern$mean_observed <- modern$pred
@

To see the effect of using our calibration factors, we will compare contemporary risk predictions from the calibrated model (y-axis) with the uncalibrated model (the x-axis). In other words, in the following graph, our averaged GBM model predicts the value shown on the x-axis, and our calibration factor adjusts that prediction to the value shown on the y-axis.

<<plot-calibrations, fig.height=4, echo=FALSE>>=
ggplot(modern, aes(pred, mean_observed)) + geom_point() +
  facet_wrap(~class) + coord_fixed(ratio = 1) +
  xlim(0, 0.9) + ylim(0, 0.9) +
  geom_abline(intercept = 0, slope = 1, lty = 3) +
  xlab("Predicted") + ylab("Calibrated prediction")
@

We will also save a version of our predictions where we build the predictions based on the average predictions across geologic stage models. We've already built these models. We will take the average predictions across replicated fits and geologic stages.

<<predict-risk-modern-average-version>>=
predictions_stage_avg <- laply(stage_models, function(x) {
    p1 <- laply(x, function(y) gbm::predict.gbm(y, newdata = modern,
  type = "response", n.trees = 300))
  p2 <- apply(p1, 2, mean)
  p2
})
modern$pred_stage_avg <- apply(predictions_stage_avg, 2, mean)
@

% We will save the \texttt{modern} data frame for future use.

<<save-modern>>=
saveRDS(modern, file = "../data/modern-predictions.rds")
@

We can compare the predictions from the averaged stage models with the predictions from the GBMs based on all Neogene data pooled together. Note that we're not comparing the calibrated predictions here:

<<compare-neogene-gbm-to-stage-models, fig.height=4.5>>=
ggplot(modern, aes(pred, pred_stage_avg)) + geom_point() +
  facet_wrap(~class) + geom_abline(intercept = 0, slope = 1) +
  xlab("Neogene GBM") + ylab("Stage-level GBMs averaged")
@
% modern$mean_observed <- modern$pred_stage_avg

% Next, we will merge these predictions with our contemporary spatial observations. At the same time, we will merge in the data from Ref.\ \cite{halpern2011} Ref.\ \cite{spalding2007}.

<<merge-predictions-spatial, child='merge-predictions-spatial-child.Rnw', echo=FALSE>>=
@

We can look at the distribution of predicted extinction probability. Note that the x-axis is log distributed:

% TODO - Seth - reduce size of panel labels
<<plot-density-risk, fig.height=4, echo=FALSE>>=
ggplot(d.eco.filled, aes(mean_observed + 0.001)) +
  geom_histogram(binwidth = 0.3) + facet_wrap(~class) + scale_x_log10() +
  ylab("Density") + xlab("Predicted extinction probabilty")
@

We can also look at the distribution of our predictions by biogeographic province \cite{spalding2007} and class (Fig.~\ref{fig:plot-density-risk-by-province}).

<<plot-density-risk-by-province, fig.width=17, fig.height=13, out.width="7in", fig.cap="The distribution of intrinsic extinction risk by biogeographic province \\cite{spalding2007} (panels) and taxonomic class (colours). Note the log transformed x-axis.", echo=FALSE>>=
# merge in province names:
er <- readShapePoly("../data/MEOW2/meow_ecos.shp")
prov_names <- er@data[,c("PROVINCE", "PROV_CODE")]
prov_names <- prov_names[!duplicated(prov_names), ]
temp <- plyr::join(d.eco.filled, prov_names, by = "PROV_CODE")
# add "0" to the single digit numbers for alphabetical ordering:
temp$PROV_CODE[nchar(temp$PROV_CODE) == 1] <-
  paste0("0", temp$PROV_CODE[nchar(temp$PROV_CODE) == 1])
temp <- transform(temp, PROV_pretty = paste(PROV_CODE, PROVINCE))
ggplot(temp, aes(mean_observed + 0.001)) +
  geom_histogram(aes(fill = class, colour = class),
    position = "stack", alpha = 0.5, binwidth = 0.4) +
  facet_wrap(~ PROV_pretty) +
  scale_x_log10() +
  ylab("Number of genera") + xlab("Predicted extinction probabilty")
@

\subsection{Mapping risk predictions using contemporary species distributions}

Now, we will create Fig.~2 and Fig.~3 from the paper.

<<plot-class-maps, results='hide'>>=
# create the dataset to map:
load("../data/by.prov.classes.rda")
er <- maptools::readShapePoly("../data/MEOW2/meow_ecos.shp")
er@data$id = rownames(er@data)
er_points = ggplot2::fortify(er, region = "id")
er_dat_class <- plyr::join(er_points, er@data, by = "id")
er_dat_class <- plyr::join(er_dat_class, by.prov.classes, by = "PROV_CODE")

# make the figure:
pdf("../figs/class-risk-maps-mean-log-ext.pdf", width = 6.45, height = 5.4)
map_class_ext(er_dat_class, yticks = c(0.005, 0.01, 0.02, 0.05, 0.10, 0.20),
  min_prov_genera = 10, col_range = TRUE)
dev.off()
@

<<plot-hotspots, results='hide'>>=
load("../data/by.prov.all.rda")
er_dat <- plyr::join(er_points, er@data, by = "id")
er_dat <- plyr::join(er_dat, by.prov.all, by = "PROV_CODE")
pdf("../figs/hotspots.pdf", width = 7, height = 4)
par(mar = c(0, 0, 0, 0), oma = c(0, 0, 0, 0))
map_hotspots(er_dat, min_prov_genera = 100)
dev.off()
@

\section{Model exploration and sensitivity analyses}

\subsection{The effect of interpolation of OBIS records}

We can create a version of the final maps without bounding-box interpolation of the OBIS records.

<<predict-no-bounding-box, fig.width=7, fig.height=4, out.width="6.25in">>=
# Read in raw (not interpolated) contemporary data:
temp_dat <- readRDS("../data/stand-predictors-cen-obis.rds")
modern_raw <- subset(temp_dat, stage == "Modern_raw")
modern_raw$stage <- "Modern"
rm(temp_dat)

# Predict from the models we previously ran:
predictions_raw <- laply(m, function(x)
  gbm::predict.gbm(x, newdata = modern_raw, type = "response",
    n.trees = 300))
modern_raw$pred_raw <- apply(predictions_raw, 2, mean)

# Calibrate:
modern_raw$gbm_pred_binned <- assign_bins(modern_raw$pred_raw)
modern_raw <- plyr::join(modern_raw,
  val_test_summarized[,c("class", "gbm_pred_binned", "mean_observed")],
  by = c("class", "gbm_pred_binned"))
modern_raw <- plyr::rename(modern_raw,
  c("mean_observed" = "mean_observed_raw"))

# Bring in interpolated version for comparison:
modern_raw <- plyr::join(modern_raw,
  modern[,c("class", "genus", "mean_observed")])

ggplot(modern_raw, aes(mean_observed, mean_observed_raw)) +
  geom_point(alpha = 0.2) + facet_wrap(~class) +
  xlab("Extinction probability (interpolated)") +
  ylab("Extinction probability (no interpolation)") +
  geom_abline(intercept = 0, slope = 1, lty = 3)
@

<<compare-bounding-box-build-data>>=
modern_raw_long <- reshape2::melt(modern_raw, id.vars = c("class", "genus"),
  measure.vars = c("richness", "occupancy", "occurrences", "min.lat", "max.lat",
    "mean.lat", "great.circle"))
modern_raw_long <- plyr::rename(modern_raw_long,
  c("value" = "value_raw"))
modern_long <- reshape2::melt(modern, id.vars = c("class", "genus"),
  measure.vars = c("richness", "occupancy", "occurrences", "min.lat", "max.lat",
    "mean.lat", "great.circle"))
modern_long <- plyr::join(modern_long, modern_raw_long, by = c("class", "genus", "variable"))
@

<<compare-bounding-box-occupancy, fig.width=9, fig.height=6, out.width="6.25in">>=
ggplot(subset(modern_long, variable %in% c("occupancy")), 
  aes(value, value_raw)) +
  geom_point(alpha = 0.2) + 
  geom_abline(intercept = 0, slope = 1, lty = 3) +
  facet_grid(variable~class, scales = "free") +
  xlab("Interpolated value") + ylab("Raw value")
@

<<compare-bounding-box-lat, fig.width=9, fig.height=6, out.width="6.25in">>=
ggplot(subset(modern_long, variable %in% c("min.lat", "max.lat", "mean.lat")), 
  aes(value, value_raw)) +
  geom_point(alpha = 0.2) + facet_grid(variable~class, scales = "free") +
  geom_abline(intercept = 0, slope = 1, lty = 3) +
  xlab("Interpolated value") + ylab("Raw value")
@

<<compare-bounding-box-gcd, fig.width=9, fig.height=3, out.width="6.25in">>=
ggplot(subset(modern_long, variable %in% c("great.circle")), 
  aes(value, value_raw)) +
  geom_point(alpha = 0.2) + facet_grid(variable~class, scales = "free") +
  geom_abline(intercept = 0, slope = 1, lty = 3) +
  xlab("Interpolated value") + ylab("Raw value")
@

% Next we'll re-create the main maps with the raw contemporary data:

<<prepare-bounding-box-comparison>>=
d.eco.filled_raw <- readRDS("../data/obis_prov_obs_no_interp.rds")
d.eco.filled_raw$n_obs <- NULL

# Merge occurrence data with risk predictions:
d.eco.filled_raw <- merge(d.eco.filled_raw, modern_raw, by = "genus", all.x = FALSE)

# And calculate mean values by class-province or for the provinces overall:
by.prov.classes.raw <- dplyr::summarise(dplyr::group_by(na.omit(d.eco.filled_raw),
    class, PROV_CODE),
  mean.ext = mean(log(mean_observed_raw + 0.001)),
  N.gen = length(unique(genus)))

by.prov.all.raw <- dplyr::summarise(dplyr::group_by(na.omit(d.eco.filled_raw),
    PROV_CODE),
  mean.ext = mean(log(mean_observed_raw + 0.001)),
  N.gen = length(unique(genus)))

# Create some fake columns: (we need these columns for the plotting functions)
by.prov.all.raw$Halpern <- 1
by.prov.all.raw$Burrows <- 1

# Create the dataset to map:
er_dat_class_raw <- plyr::join(er_points, er@data, by = "id")
er_dat_class_raw <- plyr::join(er_dat_class_raw, by.prov.classes.raw, by = "PROV_CODE")
@

% The follow code produces Fig.~\ref{fig:plot-class-prov-ext-raw-ranges}.

<<plot-class-prov-ext-raw-ranges, fig.cap="Mean predicted extinction susceptibility of genera inhabiting different ocean biogeographic provinces \\cite{spalding2007} for each of the eight major groups considered, as in Fig.~3, but \\textbf{with predictions based on raw ranges in OBIS without the within-realm minimum bounding box interpolation}. Scale bars on the right indicate the range of log extinction susceptibility values for a given group, and this scale is used to plot mean extinction susceptibility heatmaps on the left.", fig.width=6.45, fig.height=5.4, out.width="6.25in">>=
# Make the class figure:
map_class_ext(er_dat_class_raw,
  yticks = c(0.005, 0.01, 0.02, 0.05, 0.10, 0.20),
  min_prov_genera = 10, col_range = TRUE)
@

% The follow code produces Fig.~\ref{fig:no-bounding-box-overall-map}.

<<no-bounding-box-overall-map, fig.cap="Mean predicted extinction susceptibility, \\ldots \\textbf{no bounding box}.", fig.width=6, fig.height=4, outwidth="6in">>=
# Make the overall figure:
er_dat_raw <- plyr::join(er_points, er@data, by = "id")
er_dat_raw <- plyr::join(er_dat_raw, by.prov.all.raw, by = "PROV_CODE")
par(mar = c(0, 0, 0, 0), oma = c(0, 0, 0, 0))
map_hotspots(er_dat_raw, min_prov_genera = 100, hotspots = FALSE)
@

\subsection{Jackknife analysis}

We can recreate the global intrinsic extinction probability map leaving out each taxonomic class in succession in a jackknife analysis. This gives us an idea if any one class is driving the pattern.

<<jackknife-map, fig.cap="Jackknife plot. TODO Fill in this caption.", fig.width=7, fig.height=9, out.width="6.25in">>=
load("../data/by.prov.all.jk.rda")
classes <- as.character(unique(modern$class))
par(mfrow = c(4, 2))
par(mar = c(0, 0, 1.5, 0), oma = c(2, 2, 2, 2))
for(i in 1:length(classes)) {
  er_dat <- plyr::join(er_points, er@data, by = "id")
  er_dat <- plyr::join(er_dat, by.prov.all.jk[[i]], by = "PROV_CODE")
  map_hotspots(er_dat, min_prov_genera = 100, hotspots = FALSE)
  mtext(paste("Exclude", classes[i]), line = -0.5)
}
@

\subsection{The role of the tropic in risk predictions}

TODO this section/figure will no longer be about the tropics.
We can inspect the role of tropical regions. Earlier we defined ``tropical'' as less than 30$^{\circ}$ absolute latitude. This code produces Fig.~\ref{fig:test-tropical-drivers}.

<<predictors-vs-risk, fig.width=18, fig.height=11.5, out.width="7in", fig.cap="Log-transformed mean intrinsic risk of genera in a biogeographic province \\cite{spalding2007} versus various predictors for that province. Each point represents a single biogeographic province. Lines and gray-shaded regions indicate linear regressions and 95\\% confidence intervals.">>=
by.prov.classes.long <- reshape2::melt(by.prov.classes, id.vars =
  c("PROV_CODE", "class"), measure.vars =
  c("mean.lat.range", "mean.occupancy", "mean.gcd", "log_OBIS_records",
    "mean.richness"))
by.prov.classes.long <- plyr::join(by.prov.classes.long, by.prov.classes[,
  c("PROV_CODE", "class", "mean.ext")],
  by = c("PROV_CODE", "class"))

ggplot(by.prov.classes.long,
  aes(value, mean.ext)) +
  geom_point(alpha = 0.7) +
  facet_wrap(variable~class, scales = "free") +
  stat_smooth(method = "lm", se = TRUE, lwd = 1.5) +
  ylab("log(Mean intrinsic extinction risk)") +
  xlab("Predictor value")
@

\subsection{Exploring contemporary sampling intensity}

We will plot the number of OBIS records per province --- see Fig.~\ref{fig:plot-n-genera-prov}.

<<plot-n-genera-prov, fig.cap="Number of OBIS occurrence records for each biogeographic province \\cite{spalding2007}. Scale bars on the right (log-distributed scale) indicate the range for a given group, and this scale is used to plot relative sampling intensity heatmaps.", fig.width=6.25, fig.height=4.8, out.width="6in">>=
map_class_ext(er_dat_class, plot_column = "log_OBIS_records",
  min_prov_genera = 0, ylab = "Number of OBIS records",
  yticks = c(2, 20, 200, 2000, 20000),
  col_pal = RColorBrewer::brewer.pal(9, "YlGnBu"))
@

\subsection{Exploring the distribution of the predictors}

<<plot-n-gen-genera-prov, fig.cap="Number of genera.", fig.width=6.25, fig.height=4.8, out.width="6in">>=
er_dat_class$log.N.gen <- log(er_dat_class$N.gen)
map_class_ext(er_dat_class, plot_column = "log.N.gen",
  min_prov_genera = 0, ylab = "Number of genera",
  yticks = c(1, 10, 100, 500),
  col_pal = RColorBrewer::brewer.pal(9, "YlGnBu"))
@

<<plot-gcd-genera-prov, fig.cap="Mean GCD.", fig.width=6.25, fig.height=4.8, out.width="6in">>=
er_dat_class$log.mean.gcd <- log(er_dat_class$mean.gcd)
map_class_ext(er_dat_class, plot_column = "log.mean.gcd",
  min_prov_genera = 0, ylab = "Mean great circle distance",
  yticks = c(10000, 20000),
  col_pal = RColorBrewer::brewer.pal(9, "YlGnBu"))
@

<<plot-richness-genera-prov, fig.cap="Mean richness.", fig.width=6.25, fig.height=4.8, out.width="6in">>=
er_dat_class$log.mean.richness <- log(er_dat_class$mean.richness)
map_class_ext(er_dat_class, plot_column = "log.mean.richness",
  min_prov_genera = 0, ylab = "Mean standardized richness (0-1)",
  yticks = c(0.1, 0.2, 0.5, 1),
  col_pal = RColorBrewer::brewer.pal(9, "YlGnBu"))
@


\subsection{Alternative maps of contemporary extinction risk}

We will look at the effect of the changing the cutoff for the minimum-genera-per-province-class combination. In other words, as we increase this threshold, some classes with fewer genera in a given province are removed.

TODO THESE DON'T MATCH FIG 3 RIGHT NOW - WHY?

<<min-gen-thresh-sensitivity, fig.height=8, fig.width=13>>=
par(mfrow = c(2, 2))
par(mar = c(0, 0, 2, 0), oma = c(2, 2, 2, 2))
map_hotspots(er_dat, min_prov_genera = 25, hotspots = FALSE)
mtext("Min. genera = 25", cex = 2)
map_hotspots(er_dat, min_prov_genera = 50, hotspots = FALSE)
mtext("Min. genera = 50", cex = 2)
map_hotspots(er_dat, min_prov_genera = 100, hotspots = FALSE)
mtext("Min. genera = 100", cex = 2)
map_hotspots(er_dat, min_prov_genera = 200, hotspots = FALSE)
mtext("Min. genera = 200", cex = 2)
@

\clearpage
\bibliographystyle{science}
\bibliography{jshort,risksupp}

\clearpage

\section{Main Figures}

\begin{center}
  \includegraphics[width=4.86in]{../figs/partial-plot-base.pdf}\\
  \smallskip
  Figure 1
\end{center}

\clearpage

\begin{center}
  \includegraphics[width=4.86in]{../figs/class-risk-maps-mean-log-ext.pdf}\\
  \smallskip
  Figure 2
\end{center}

\clearpage

\begin{center}
  \includegraphics[width=4.86in]{../figs/hotspots.pdf}\\
  \smallskip
  Figure 3
\end{center}

\newpage

\section{Supplementary Figures}

\end{document}
