<<make-partial-dat>>=

####################################
# First, we will write a function to fit the GBM models to a given stage:
# shape-data-partial-plots:
# (This function now also bootstraps the data each time to provide a measure
# of variability.)
fit_stage_models <- function(dat, stage_name, bootstrap = FALSE) {
  if(stage_name == "all") {
    if(bootstrap) {
      nrow_dat <- nrow(dat) # get first for speed
      d <- dat[sample(seq_len(nrow_dat), size = nrow_dat, replace = TRUE), ]
    } else {
      d <- dat
    }
  } else {
    if(bootstrap) {
      dat <- dat[dat$stage == stage_name, ]
      nrow_dat <- nrow(dat) # get first for speed
      d <- dat[sample(seq_len(nrow_dat), size = nrow_dat, replace = TRUE), ]
    } else {
      d <- dat[dat$stage == stage_name, ]
    }
  }
  w <- paleorisk::get_weights(d$Ex)
  weights <- ifelse(d$Ex == 1, w$ex_weight, w$sur_weight)
  gbm::gbm(Ex ~ richness + occupancy + occurrences + min.lat + max.lat +
      lat.range + mean.lat + great.circle + group, data =
      d, n.trees = NTREES, interaction.depth = INT.DEPTH,
    distribution = "bernoulli", shrinkage = SHRINKAGE, weights = weights)
}

####################################
# We will fit the models for each stage. Within each stage we will fit
# the model a number of times:
# fit-marginal-stage-models
if(!file.exists("../data/stage_models.rds")) {
  stage_models <- plyr::llply(c(stage_order, "all"), function(x)
    rlply(40, fit_stage_models(neog, stage_name = x, bootstrap = TRUE)),
      .parallel = TRUE)
  names(stage_models) <- c(stage_order, "all")
  saveRDS(stage_models, file = "../data/stage_models.rds")
} else {
  stage_models <- readRDS("../data/stage_models.rds")
}
# and for culled versions of paleo data:
cull_cuts <- c(0, sort(unique(neog$prop_comp))) # all possible
stage_models_culls <- plyr::llply(cull_cuts, function(i) {
  plyr::rlply(1, fit_stage_models(neog[neog$prop_comp >= i, ], stage_name = "all", bootstrap = FALSE))
  }, .parallel = TRUE)

####################################
# And, we will go through the stage-based models and pull out the partial
# dependence data:
# pull-out-marginal-data
vars <- c("richness", "occupancy", "occurrences", "min.lat",
  "max.lat", "lat.range", "mean.lat", "great.circle", "group")
partial_dat <- plyr::ldply(c(stage_order, "all"), function(stage_name) {
  p2 <- plyr::ldply(vars, function(var_name){
    p1 <- plyr::ldply(stage_models[[stage_name]], function(x)
      plot.gbm(x, return.grid = TRUE, i.var = var_name,
        type = "response"))
    names(p1) <- c("value", "response")
    p1$predictor <- var_name
    p1
  })
  p2$stage <- stage_name
  p2
})

# and for the culled versions:
partial_dat_culls <- plyr::ldply(1:length(cull_cuts), function(i) {
  p2 <- plyr::ldply(vars, function(var_name){
    p1 <- plyr::ldply(stage_models_culls[[i]], function(x)
      plot.gbm(x, return.grid = TRUE, i.var = var_name,
        type = "response"))
    names(p1) <- c("value", "response")
    p1$predictor <- var_name
    p1
  })
  p2$stage <- cull_cuts[i]
  p2
})

####################################
# We will get the median and interquartile range of the marginal effects:

# To do this, because of the bootstrapping, we will need to bin the predictor
# split values a bit. Different iterations will have slightly different
# predictor splits:
bin_predictor <- function(x, bins = 20) {
  itvl <- seq(min(x), max(x), length.out = bins)
  itvl[findInterval(x, itvl)]
}

group_partial_dat <- filter(partial_dat, predictor == "group")
continuous_partial_dat <- partial_dat %>%
  filter(predictor != "group") %>%
  group_by(predictor) %>%
  mutate(value = bin_predictor(value)) %>%
  as.data.frame
partial_dat <- rbind(continuous_partial_dat, group_partial_dat)

# <<summarize-marginal-effects>>=
partial_dat2 <- plyr::ddply(partial_dat,
  c("stage", "predictor", "value"),
  plyr::summarize,
  median = median(response),
  lower = quantile(response, probs = 0.10),
  upper = quantile(response, probs = 0.90))

# nn <- reshape2::melt(select(neog, richness:great.circle)) %>%
#   group_by(variable, value) %>%
#   dplyr::summarise(N = length(value)) %>%
#   dplyr::mutate(N_perc = N / max(N)) %>%
#   rename(predictor = variable) %>%
#   as.data.frame

# culled:
partial_dat2_culls <- plyr::ddply(partial_dat_culls,
  c("stage", "predictor", "value"),
  plyr::summarize,
  median = median(response),
  lower = quantile(response, probs = 0.25),
  upper = quantile(response, probs = 0.75))

####################################
# Because the taxonomic variables are categorical and the other variables are
# continuous and numeric, we will split these into separate data frames for
# plotting:
# separate-taxonomic-and-numeric-predictions
partial_groups <- partial_dat2[partial_dat2$predictor == "group", ]
partial_continuous <- partial_dat2[partial_dat2$predictor != "group", ]
groups_match <- data.frame(value = 1:length(unique(neog$group)),
  group = sort(unique(neog$group)), stringsAsFactors = FALSE)
partial_groups <- plyr::join(partial_groups, groups_match)
partial_groups$value <- NULL
partial_groups <- plyr::rename(partial_groups, c("group" = "value"))

# and for the culled paleo data:
# culled-separate-taxonomic-and-numeric-predictions:
partial_groups_culled <- partial_dat2_culls[partial_dat2_culls$predictor ==
    "group", ]
partial_groups_culled <- plyr::join(partial_groups_culled, groups_match)
partial_groups_culled$value <- NULL
partial_groups_culled <- plyr::rename(partial_groups_culled,
  c("group" = "value"))
partial_groups_culled <- plyr::rename(partial_groups_culled,
  c("stage" = "preservation_cutoff"))

partial_continuous_culled <- partial_dat2_culls[partial_dat2_culls$predictor != "group", ]
partial_continuous_culled <- plyr::rename(partial_continuous_culled,
  c("stage" = "preservation_cutoff"))
partial_continuous_culled <- plyr::ddply(partial_continuous_culled,
  c("predictor", "preservation_cutoff"), function(x) {
    data.frame(x, median_shifted = x$median - mean(x$median))
  })
@
